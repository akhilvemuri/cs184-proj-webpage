<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

    <h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
    <h1 align="middle">Project 1: Rasterizer</h1>
    <h2 align="middle">AKHIL VEMURI</h2>
    <h2 align="middle">MEIQI SUN</h2>

    <!-- Add Website URL -->
    <h2 align="middle">Website URL: <a href="https://akhilvemuri.github.io/cs184-proj-webpage/">https://akhilvemuri.github.io/cs184-proj-webpage/</a></h2>

    <br />

    <div align="center">
        <table style="width=100%">
            <tr>
                <td align="middle">
                    <img src="example_image.png" width="600px" />
                </td>
            </tr>
        </table>
    </div>

    <div>

        <h2 align="middle">Overview</h2>
        <p>
            Through assignment 1, we built a simple rasterizer that enables us to draw triangles (via normal/super sampling), perform transformations (under harmonious coordinate systems), apply barycentric coordinates, and allow texture mapping using different sampling techniques and mipmap levels. As a result, our project can take in an SVG file, and render the corresponding images on our GUI screen.
        </p>
        <p>
            The project was very interesting to implement, because during lectures, we learnt the theory and foundations behind computer graphics. They are relatively abstract to me. However, when we actually had the chance to write code for supersampling, and seeing how jaggies went away for the images we rendered, we were truly amazed by the power of the technique. Moreover, “texture mapping” sounds like an extremely complicated task where you have to transform the coordinates, find and interpolate the appropriate mipmap levels, and use nearest pixel/linear interpolation to generate the target pixel. When I see a “flat” texture and an unsmooth surface, I have no idea how to calculate the mapping formula. Yet, after carefully reviewing the slides and performing the implementation, I gradually understood the steps involved and the calculations associated.
        </p>

        <br />
        <h2 align="middle">Section I: Rasterization</h2>

        <h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
        <p>
            We rasterize the triangle by:
        </p>
        <ol style="list-style-type: decimal;">
            <li>Finding the rectangle box that perfects bounds the triangle</li>
            <li>
                Checks every sample within the box by using the center coordinate of the pixel and determine whether it is inside the triangle using three line tests <br />
            </li>
            <ol style="list-style-type: none;">
                <li>
                    [Challenges: At first, I noticed that some triangles were colored while others were not. So I wrote out the math corresponding to my code, and realized that there are “clockwise” triangles and “counterclockwise” triangles. So I would need to incorporate both triangles that passed all three line tests, and triangles that didn’t pass any of the tests.] <br />
                </li>

            </ol>
            <li>For each sample within the triangles, we fill in the pixel with the corresponding color</li>
        </ol>

        <p>
            Our algorithm is no worse than the one that checks each sample within the bounding box because this is the algorithm we implemented.
        </p>

        <div align="middle">
            <table style="width=100%">

                <tr>
                    <img src="images/task_1.png" align="middle" width="400px" />
                    <figcaption align="middle">Fig 1: Task 1, basic/test4.svg.</figcaption>
                </tr>

            </table>
        </div>


        <h3 align="middle">Part 2: Antialiasing triangles</h3>
        <h4> Supersampling algorithm/data structure: </h4>
        <ol style="list-style-type: decimal;">
            <li>
                Iterate over all the pixels within the bounding box of the triangle
            </li>
            <li>
                Calculate the sqrt of the number of samples we need -> “increment”
            </li>
            <li>
                Start from the corner of the pixel, and gradually increment/move with step size: 1/increment on both the x and y axes
            </li>
            <li>
                For each of the finer samples we collect, we mark on the sample_buffer (We chose to use an <b>1-D array</b> ) if the point is within the triangle
            </li>
            <ol style="list-style-type: none;">
                <li>
                    [Setup of sample_buffer: we need to resize it to width*height*sample_rate, so that we have enough space in the <b>1-D array</b> to store all the samples we collected]
                </li>

            </ol>
            <li>
                Resolve the pixels from sample_buffer to the framebuffer (where we actually fill in the pixels)
            </li>
            <ol style="list-style-type: disc;">
                <li>
                    For each element inside the sample_buffer, we convert the variable from type Color to a list of floats corresponding to the r, g, and b value of the pixel
                </li>
                <li>
                    We mark it onto the rgb_framebuffer_target with the average of the r, g, b values of all samples within the given pixel
                </li>

                [The size of the target is width*height*3]

                <li>
                    We fill in the pixel with color according to the rgb_framebuffer_target: Here, color needs to be converted from the float back to a Color type variable

                </li>

            </ol>
        </ol>


        <h4>
            Why is supersampling useful?
        </h4>
        <p>
            Supersampling is useful because it allows us to evaluate at finer details and take the average of the different samples. It allows us to first get a higher resolution picture, and then downsample it, creating smoother pixels and curves (because the intensity of the pixels vary as well)

        </p>

        <h4>
            Modifications to the pipeline:
        </h4>
        <ol style="list-style-type: disc;">
            <li>
                Create the image with higher resolution and then downsample it to match the dimension of the screen
            </li>
            <li>
                Rely on the help of a sample_buffer: we don’t fill in the pixels directly, but instead first store the values in a buffer, take the average of all samples corresponding to the same pixel, and in the end fill in the pixels
            </li>

        </ol>
        <h4>
            Observations:
        </h4>


        We saw significant anti-aliasing effects with super sampling, because we are allowed to color the pixels with different intensities according to the portion of the pixel that lies inside the triangle. Therefore, we enabled smoother transitions between the pixels, and the graph gets antialiased.
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <figure>

                            <img src="images/basic_4_sample_1.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 2: Sampling Rate: 1.</figcaption>
                        </figure>

                    </td>
                    <td>
                        <figure>
                            <img src="images/basic_4_sample_4.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 3: Sampling Rate: 4.</figcaption>

                        </figure>
                    </td>
                </tr>


                <tr>
                    <td>
                        <figure>
                            <img src="images/basic_4_sample_9.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 4: Sampling Rate: 9.</figcaption>

                        </figure>
                    </td>
                    <td>
                        <figure>
                            <img src="images/basic_4_sample_16.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 5: Sampling Rate: 16.</figcaption>
                        </figure>

                    </td>
                </tr>
            </table>
        </div>
        <br />
        <br />


        <h3 align="middle">Part 3: Transforms</h3>
        Cubeman is running while pointing forward! This requires him to have his right leg tilted forward, and back lag curled up because he is running. His left arm is also bent, because he is running forward to the right. His right arm stays straight, because while running, he is simultaneously pointing forward.
        <div align="middle">
            <table style="width=100%">

                <tr>
                    <img src="images/task_3.png" align="middle" width="400px" />
                    <figcaption align="middle">Fig 6: Task 3, Running Cubeman.</figcaption>
                </tr>

            </table>
        </div>

        <br />
        <h2 align="middle">Section II: Sampling</h2>

        <h3 align="middle">Part 4: Barycentric coordinates</h3>
        Barycentric coordinates: Expressing each point inside the triangle as a three-element tuple with reference to the three vertices of the triangles. Here, alpha, beta, and gamma act as weights to help us locate a specific point inside the triangle, and they should always sum to 1. This information can be used to interpolate the vertex information across the triangle.
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/task_4.png" align="middle" width="400px" />
                        <figcaption align="middle"> Fig 7: Barycentric Coord Triangle.</figcaption>
                    </td>
                    <td>
                        <img src="images/task_7.png" align="middle" width="400px" />
                        <figcaption align="middle"> Fig 8: basic/test7.svg.</figcaption>
                    </td>
                </tr>

            </table>
        </div>
        <br />
        <br />


        <h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
        <h4>
            Background:
        </h4>
        Pixel sampling refers to the process of determining the color of a pixel in screen space by sampling its values from the underlying image. This technique is often used for texture mapping, which involves mapping a 2D image onto a 3D surface, which is what we implemented here.
        We implemented two versions, both nearest and bilinear pixel sampling methods, to determine the color of each pixel on the 3D surface. The nearest pixel sampling method, also known as nearest neighbor interpolation, simply chooses the color of the closest texel (texture element) to the sample point. This method is fast, but it can result in a "blocky" or pixelated appearance when the texture is magnified.
        The bilinear pixel sampling method, on the other hand, uses the weighted average of the four closest texels to the sample point via LERPing. This method provides smoother results as it takes into account the surrounding texel values and blends them together. However, it is computationally more expensive than nearest neighbor interpolation.
        <h4>
            Observations:
        </h4>
        As you can see in Figures 9-12 below, bilinear sampling hides the aliasing evident in the nearest neighbor sampling images. Supersampling improves the quality of both sampling methods. Also, the antialiasing effect of bilinear interpolation is much more obvious when sampling rate is 1; whereas when sampling rate = 16, the difference between nearest neighbor and bilinear interpolation is not very obvious anymore. In theory, the largest differences between the two methods should be most prominent when the screen space is magnified relative to the texture space (i.e. small L metric) at the sample point. Then the nearest-neighbor approach will effectively magnify the pixelation in texel space into screen space since 1 texel maps to multiple pixels under a magnification regime. Also, when we the sample rate is 1, nearest neighbor is reaching out to the nearest pixel under the original resolution for color. However, when supersampling is already performed, the nearest neighbor method reaches out to a nearest sample point within the pixel (under original resolution), so the effect of bilinear interpolation under this case would be less obvious.
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <figure>
                            <img src="images/task_5_near_1.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 9: Nearest Neighbor (sample rate = 1).</figcaption>
                        </figure>
                    </td>
                    <td>
                        <figure>
                            <img src="images/task_5_bilinear_1.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 10: Bilinear (sample rate = 1).</figcaption>
                        </figure>

                    </td>
                </tr>


                <tr>
                    <td>
                        <figure>
                            <img src="images/task_5_near_16.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 11: Nearest Neighbor (sample rate = 16).</figcaption>
                        </figure>
                    </td>
                    <td>
                        <figure>
                            <img src="images/task_5_bilinear_16.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 12: Bilinear (sample rate = 16).</figcaption>
                        </figure>
                    </td>
                </tr>

            </table>
        </div>
        <br />
        <br />


        <h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
        <h4>
            Background:
        </h4>
        Level sampling refers to the process of selecting the level of detail to use throughout a texture during texture mapping and minification. This is important because different parts of a 3D model may be viewed at different distances, requiring different levels of detail in the textures used for mapping.
        Mipmaps formulate a collection of downsampled (texel-averaged) textures from which sensible texel values can be passed back to screen space pixels. The process for identifying the proper mipmap level to retrieve texel values from for a given pixel in screen space is called level sampling. Fundamentally, we implemented level sampling by using the columns of the map's Jacobian matrix. The magnitude of the column vectors of the Jacobian provide an approximate measure of the local pixel footprint in texture space.
        From this information, we are able to calculate which mipmap level is best suited to color a certain part of screen space based on the degree of minification induced by the map at that local region.

        <h4>
            Tradeoffs:
        </h4>
        Pixel Sampling:
        <ol style="list-style-type: disc;">
            <li>
                Speed: Nearest neighbor interpolation is faster than bilinear interpolation since it requires less computation.
            </li>
            <li>
                Memory Usage: Both methods have similar memory requirements as they both require the same texture data to be stored.
            </li>
            <li>
                Antialiasing Power: Bilinear interpolation provides better antialiasing compared to nearest neighbor interpolation since it blends the colors of surrounding texels, resulting in smoother textures.
            </li>
        </ol>
        Level Sampling:
        <ol style="list-style-type: disc;">
            <li>
                Speed: Level sampling is generally faster than both pixel sampling methods since it uses the appropriate level of detail based on the distance from the camera, and therefore, reduces the amount of computation required.
            </li>
            <li>
                Memory Usage: Level sampling requires more memory compared to pixel sampling because it requires the mipmap hierarchy to be stored in memory.
            </li>
            <li>
                Antialiasing Power: Level sampling provides good antialiasing results because it adjusts the level of detail based on the distance from the camera, and therefore, reduces the visibility of pixelation.
            </li>
        </ol>
        Number of Samples per Pixel:
        <ol style="list-style-type: disc;">
            <li>
                Speed: Increasing the number of samples per pixel will reduce antialiasing, but will increase computation time, as more samples need to be calculated.
            </li>
            <li>
                Memory Usage: The number of samples per pixel does not have a significant impact on memory usage.
            </li>
            <li>
                Antialiasing Power: Increasing the number of samples per pixel will improve antialiasing since more samples will be used to determine the color of each pixel, making in a smoother image.
            </li>
        </ol>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <figure>
                            <img src="images/task_6_zero_nearest.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 13: L_ZERO, P_NEAREST.</figcaption>
                        </figure>
                    </td>
                    <td>
                        <figure>
                            <img src="images/task_6_zero_bilinear.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 14: L_ZERO, P_LINEAR.</figcaption>
                        </figure>

                    </td>
                </tr>


                <tr>
                    <td>
                        <figure>
                            <img src="images/task_6_nearest_nearest.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 15: L_NEAREST, P_NEAREST.</figcaption>
                        </figure>
                    </td>
                    <td>
                        <figure>
                            <img src="images/task_6_nearest_bilinear.png" align="middle" width="400px" />
                            <figcaption align="middle"> Fig 16: L_NEAREST, P_LINEAR.</figcaption>
                        </figure>
                    </td>
                </tr>

            </table>
        </div>
        <br />
        <br />

        <h2 align="middle">Section III: Art Competition</h2>
        <h3 align="middle">Part 7: Draw something interesting!</h3>
        For our art submssion, we drew a low-poly, triangulated image of a bird sitting on a tree. While the original image was sourced from Google, we used a script to modify it.

        <br \=\ />
        <br \=\ />

        First, we identified sample points along defining edges of the picture using Canny edge detection. This method involves smoothing the image using a Gaussian filter, computing the gradient across the image matrix, and determining strong and weak edges by applying a threshold.
        Next, we applied the Delaunay triangulation algorithm to connect these sample points, forming a multilayered triangle mesh that gives the artwork its characteristic low-poly, triangular appearance.
        Finally, we had to add the colors to our picture. Each triangle's color was determined by the triangle's "average" color in the original image. This allowed us to map each triangle to a single fill, which would keep the drawing smooth and help enhance the overall 3Dness of the picture.
        To create the actual svg file, we simply wrote a template for a general polygon tag and replicated that for each triangle, filling in the sample points and fill color as necessary.


        <br />
        <br />

        There are many ways in which this drawing can be improved upon. The parameters of threshold, blur, and sampling rate could all affect which sample points are chosen and how fine-grained each triangle would look. Having more triangles would approximate the original image closer, but having less could help reduce complexity in the image, therefore reducing the amount of high frequency signals.
        The size and shape of each triangle is another factor. This can heavily affect what the color scheme will look like as well as whether the image is comprehensible. As a future improvement, we would want to incorporate multiple gradient colors or different types of polygons to allow for more flexibility across the drawing in general.

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="competition.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>
    </div>

</body>
</html>

